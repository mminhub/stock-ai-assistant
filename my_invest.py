import streamlit as st
import feedparser
import yfinance as yf
import requests
from bs4 import BeautifulSoup
import urllib.parse
import re
import time

# ==============================================================================
# [1] ì„¤ì •
# ==============================================================================
st.set_page_config(page_title="Strategic AI Partner", layout="wide")

if "GOOGLE_API_KEY" not in st.secrets:
    st.error("ğŸš¨ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

API_KEY = st.secrets["GOOGLE_API_KEY"]
RELAY_MODELS = ["gemini-2.5-flash", "gemini-2.0-flash"]

# í”„ë¡¬í”„íŠ¸: í˜•ì‹ì„ ì¢€ ë” ë‹¨ìˆœí•˜ê²Œ ìš”ì²­ (ì˜¤ë¥˜ ë°©ì§€)
PROMPT_BRIEFING = """
You are a CIO. Analyze these 5 headlines.
Return result in KOREAN. Use this format:

[MARKET]
SCORE: (0-100)
VIEW: (One sentence summary)

[NEWS]
1. ACTION: (Buy/Sell/Hold) | REASON: (Reason)
2. ACTION: (Buy/Sell/Hold) | REASON: (Reason)
3. ACTION: (Buy/Sell/Hold) | REASON: (Reason)
4. ACTION: (Buy/Sell/Hold) | REASON: (Reason)
5. ACTION: (Buy/Sell/Hold) | REASON: (Reason)
"""

PROMPT_DEEP = """
Analyze this news. Format in Korean:
GRADE: [S/A/B/C]
ACTION: [ë§¤ìˆ˜/ë§¤ë„/ê´€ë§] | [Reason]
PROBABILITY: [0-100] | [Trend] | [Impact]
SUMMARY: -Fact
RISK: -Risk
"""

# ==============================================================================
# [2] ìœ í‹¸ë¦¬í‹° (í…ìŠ¤íŠ¸ ì²­ì†Œ & AI í†µì‹ )
# ==============================================================================
def clean_text(text):
    """ì œëª©ì´ë‚˜ ë‚´ìš©ì— ë¶™ì€ ì´ìƒí•œ ê¸°í˜¸ ì œê±°"""
    if not text: return ""
    # JSON ê´„í˜¸, ë”°ì˜´í‘œ ë“± ì œê±°
    text = re.sub(r'[\[\]\{\}\"]', '', text)
    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    return text.strip()

def call_ai_relay(prompt):
    for model in RELAY_MODELS:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={API_KEY}"
        headers = {'Content-Type': 'application/json'}
        data = {"contents": [{"parts": [{"text": prompt}]}]}
        
        try:
            res = requests.post(url, headers=headers, json=data, timeout=20)
            if res.status_code == 200:
                return res.json()['candidates'][0]['content']['parts'][0]['text'], model
            elif res.status_code == 429:
                time.sleep(2)
                continue
        except:
            continue
    return None, "AI ì—°ê²° ì‹¤íŒ¨"

@st.cache_data(ttl=600)
def fetch_market_data():
    try:
        tickers = ['^TNX', '^VIX', 'BTC-USD', 'GC=F', '^GSPC', '^IXIC']
        df = yf.download(tickers, period="5d", progress=False)['Close'].ffill()
        last = df.iloc[-1]
        prev = df.iloc[-2]
        chg = ((last - prev) / prev) * 100
    except:
        last, chg = None, None

    sites = "site:cnbc.com OR site:reuters.com OR site:bloomberg.com OR site:finance.yahoo.com"
    keywords = "Fed OR CPI OR Bitcoin OR Nvidia OR Tesla OR Apple OR Gold"
    rss_url = f"https://news.google.com/rss/search?q={urllib.parse.quote(f'{keywords} {sites}')}&hl=en-US&gl=US&ceid=US:en"
    
    feed = feedparser.parse(rss_url)
    scored_news = []
    for e in feed.entries:
        # ì œëª© ì²­ì†Œ (ì´ìƒí•œ ê¸°í˜¸ ë°©ì§€)
        e.title = clean_text(e.title)
        
        score = 0
        t = e.title.lower()
        if any(w in t for w in ['fed', 'rate', 'cpi']): score += 5
        if any(w in t for w in ['bitcoin', 'nvidia', 'tesla']): score += 4
        if score > 0: scored_news.append(e)
    
    return last, chg, scored_news[:5]

def get_article_content(link):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        res = requests.get(link, headers=headers, timeout=4)
        soup = BeautifulSoup(res.content, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        if len(text) > 200: return text[:3000]
    except:
        pass
    return "ì›ë¬¸ ì ‘ì† ë¶ˆê°€"

# ==============================================================================
# [3] íŒŒì‹± ë¡œì§
# ==============================================================================
def parse_briefing(text):
    try:
        score = re.search(r'SCORE[:\s]*(\d+)', text).group(1)
        view = re.search(r'VIEW[:\s]*(.*)', text).group(1)
    except:
        score, view = "50", "ë¶„ì„ ì¤‘..."
    return score, view

def parse_action(text, index):
    try:
        # ìˆ«ì + . + ACTION íŒ¨í„´ ë“±ì„ ìœ ì—°í•˜ê²Œ ì°¾ìŒ
        pattern = f"{index}\.\s*ACTION[:\s]*(.*)"
        match = re.search(pattern, text, re.IGNORECASE)
        
        if not match: # ëª» ì°¾ìœ¼ë©´ ë‹¤ë¥¸ íŒ¨í„´ ì‹œë„
             pattern = f"NEWS[\s_]*{index}[\s_]*ACTION[:\s]*(.*)"
             match = re.search(pattern, text, re.IGNORECASE)

        line = match.group(1) if match else "Hold | ëŒ€ê¸°"
        if "|" in line:
            return line.split("|", 1)
        return line, ""
    except:
        return "Hold", "Parsing Error"

# ==============================================================================
# [4] ë©”ì¸ ì‹¤í–‰
# ==============================================================================
def main():
    st.title("â˜• Strategic AI Partner")
    
    # [ì¤‘ìš”] ì •ë°€ ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ê¸ˆê³ (Dictionary) ì´ˆê¸°í™”
    if 'deep_results' not in st.session_state:
        st.session_state['deep_results'] = {}

    # 1ì°¨ ë¸Œë¦¬í•‘ (ìë™)
    if 'briefing_data' not in st.session_state:
        status = st.info("ğŸ”„ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘... (ì•½ 15ì´ˆ)")
        
        last, chg, news = fetch_market_data()
        st.session_state['market_raw'] = (last, chg, news)
        
        news_txt = "\n".join([f"[{i+1}] {n.title} (Summary: {n.get('description','')[:150]})" for i, n in enumerate(news)])
        
        ai_res, used_model = call_ai_relay(f"{PROMPT_BRIEFING}\n{news_txt}")
        
        if ai_res:
            st.session_state['briefing_data'] = ai_res
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ({used_model})")
            time.sleep(1)
            status.empty()
        else:
            status.error("ë¶„ì„ ì‹¤íŒ¨. ì ì‹œ í›„ ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.")
            st.stop()

    last, chg, news = st.session_state['market_raw']
    briefing = st.session_state['briefing_data']

    # ì‹œì¥ ì§€í‘œ
    if last is not None:
        cols = st.columns(6)
        metrics = [("US 10Y", '^TNX'), ("VIX", '^VIX'), ("S&P 500", '^GSPC'), 
                   ("Nasdaq", '^IXIC'), ("BTC", 'BTC-USD'), ("Gold", 'GC=F')]
        for i, (l, k) in enumerate(metrics):
            cols[i].metric(l, f"{last.get(k,0):,.2f}", f"{chg.get(k,0):.2f}%")

    st.divider()

    score, view = parse_briefing(briefing)
    c1, c2 = st.columns([1, 3])
    with c1: 
        st.metric("íˆ¬ì ë‚ ì”¨", f"{score}/100")
        st.progress(int(score))
    with c2: 
        st.info(f"ğŸ”­ {clean_text(view)}")

    st.subheader("ğŸ“° ë‰´ìŠ¤ ë¸Œë¦¬í•‘")

    for i, n in enumerate(news):
        act, rsn = parse_action(briefing, i+1)
        color = "green" if "Buy" in act or "ë§¤ìˆ˜" in act else "red" if "Sell" in act or "ë§¤ë„" in act else "orange"
        
        with st.container():
            # ì œëª© ì¶œë ¥ (ì´ìƒí•œ ê¸°í˜¸ ì œê±°ë¨)
            clean_title = clean_text(n.title)
            st.markdown(f":{color}[â—] **[{act.strip()}]** {clean_title}")
            st.caption(f"ğŸ’¡ {rsn.strip()}")
            st.markdown(f"[ì›ë¬¸ ë³´ê¸°]({n.link})")
            
            # [í•µì‹¬] ì •ë°€ ë¶„ì„ ë¡œì§ (ìœ ì§€ ê¸°ëŠ¥ í¬í•¨)
            # 1. ì´ë¯¸ ë¶„ì„í•œ ì ì´ ìˆëŠ”ì§€ ê¸ˆê³  í™•ì¸
            if i in st.session_state['deep_results']:
                # ìˆìœ¼ë©´ ë°”ë¡œ ë³´ì—¬ì¤Œ (ë²„íŠ¼ ì•ˆ ëˆŒëŸ¬ë„ ìœ ì§€ë¨)
                st.info(f"âœ… ë¶„ì„ ì™„ë£Œ ({st.session_state['deep_results'][i]['model']})")
                st.markdown(st.session_state['deep_results'][i]['content'])
                
                # ë‹¤ì‹œ ë¶„ì„í•˜ê³  ì‹¶ì„ ë•Œë¥¼ ìœ„í•œ ë²„íŠ¼
                if st.button("ë‹¤ì‹œ ë¶„ì„", key=f"re_deep_{i}"):
                    del st.session_state['deep_results'][i]
                    st.rerun()
            
            else:
                # 2. ë¶„ì„í•œ ì  ì—†ìœ¼ë©´ ë²„íŠ¼ í‘œì‹œ
                if st.button("ì •ë°€ ë¶„ì„", key=f"deep_{i}"):
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        body = get_article_content(n.link)
                        if "ë¶ˆê°€" in body: body = n.get('description', '')
                        
                        detail, u_model = call_ai_relay(f"{PROMPT_DEEP}\nTitle: {n.title}\nBody: {body}")
                        
                        if detail:
                            # 3. ê²°ê³¼ ë‚˜ì˜¤ë©´ ê¸ˆê³ ì— ì €ì¥!
                            st.session_state['deep_results'][i] = {
                                'content': detail,
                                'model': u_model
                            }
                            st.rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨í•´ì„œ ì €ì¥ëœ ê±° ë³´ì—¬ì£¼ê¸°
                        else:
                            st.error("ë¶„ì„ ì‹¤íŒ¨")
        st.divider()

    if st.button("ğŸ”„ ì „ì²´ ì´ˆê¸°í™”"):
        st.cache_data.clear()
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

if __name__ == "__main__":
    main()