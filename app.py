import streamlit as st
import feedparser
import yfinance as yf
import requests
import re
import time
from datetime import datetime
import urllib.parse
from bs4 import BeautifulSoup

# ==============================================================================
# [1] ì„¤ì • & ë³´ì•ˆ
# ==============================================================================
st.set_page_config(page_title="AI ì£¼ì‹ ê³¼ì™¸ ì„ ìƒë‹˜ (Original Only)", layout="wide")

def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]:
        return True
    
    st.title("ğŸ”’ ë¡œê·¸ì¸")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
    if st.button("ì ‘ì†"):
        if "APP_PASSWORD" in st.secrets and password == st.secrets["APP_PASSWORD"]:
            st.session_state["password_correct"] = True
            st.rerun()
        else:
            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    return False

if "APP_PASSWORD" in st.secrets:
    if not check_password(): st.stop()

if "GOOGLE_API_KEY" not in st.secrets:
    st.error("ğŸš¨ Secrets ì„¤ì •ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
    st.stop()

API_KEY = st.secrets["GOOGLE_API_KEY"]
RELAY_MODELS = ["gemini-2.5-flash", "gemini-2.0-flash-exp"]

# ==============================================================================
# [2] AI ì—”ì§„ (ì›ë¬¸ ë¶„ì„ í•„ìˆ˜)
# ==============================================================================
def clean_text(text):
    if not text: return ""
    text = re.sub(r'<[^>]+>', '', text)
    return re.sub(r'[\[\]\{\}\"]', '', text).strip()

def call_ai_relay(prompt):
    max_retries = 3
    for attempt in range(max_retries):
        for model in RELAY_MODELS:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={API_KEY}"
            headers = {'Content-Type': 'application/json'}
            data = {"contents": [{"parts": [{"text": prompt}]}]}
            
            try:
                res = requests.post(url, headers=headers, json=data, timeout=30)
                if res.status_code == 200:
                    return res.json()['candidates'][0]['content']['parts'][0]['text'], model
                elif res.status_code == 429:
                    time.sleep(5)
                    continue
                else:
                    continue
            except:
                continue
    return None, "ì„œë²„ ì‘ë‹µ ì—†ìŒ"

@st.cache_data(ttl=600)
def fetch_market_data():
    try:
        tickers = ['^TNX', '^VIX', 'BTC-USD', 'GC=F', '^GSPC', '^IXIC']
        df = yf.download(tickers, period="5d", progress=False)['Close'].ffill()
        last = df.iloc[-1]
        prev = df.iloc[-2]
        chg = ((last - prev) / prev) * 100
    except:
        last, chg = None, None

    # êµ¬ê¸€ ë‰´ìŠ¤
    rss_url = "https://news.google.com/rss/search?q=Finance+Stock&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries: return last, chg, []
        scored_news = []
        for e in feed.entries[:3]:
            e.title = clean_text(e.title)
            scored_news.append(e)
        return last, chg, scored_news
    except:
        return last, chg, []

# ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] ì€ì‹ ìˆ (Stealth) ê¸°ìˆ  ì ìš© í•¨ìˆ˜
def get_article_content(link):
    """
    ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì˜ ì°¨ë‹¨ì„ ëš«ê³  ì§„ì§œ ì›ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    1. í—¤ë” ìœ„ì¡° (ì‚¬ëŒì¸ ì²™)
    2. ì„¸ì…˜ ìœ ì§€
    3. ìµœì¢… URL ì¶”ì 
    """
    # 1. ì™„ë²½í•œ ì‚¬ëŒ í‰ë‚´ (í¬ë¡¬ ë¸Œë¼ìš°ì € í—¤ë”)
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9,ko;q=0.8',
        'Referer': 'https://www.google.com/'
    }
    
    try:
        # ì„¸ì…˜ ì‹œì‘ (ì¿ í‚¤ ìœ ì§€)
        session = requests.Session()
        
        # 2. êµ¬ê¸€ ë‰´ìŠ¤ ë§í¬ ì ‘ì† -> ì§„ì§œ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ ì¶”ì 
        res = session.get(link, headers=headers, timeout=10, allow_redirects=True)
        
        # ì ‘ì† ì„±ê³µ (200 OK)
        if res.status_code == 200:
            soup = BeautifulSoup(res.content, 'html.parser')
            
            # 3. ë³¸ë¬¸ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜ (p íƒœê·¸ë§Œ ì‹¹ ê¸ì–´ëª¨ìœ¼ê¸°)
            paragraphs = soup.find_all('p')
            
            # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥(ê´‘ê³ , ë©”ë‰´ ë“±)ì€ ë²„ë¦¬ê³ , ê¸´ ë¬¸ì¥ë§Œ ìˆ˜ì§‘
            text_content = []
            for p in paragraphs:
                text = p.get_text().strip()
                if len(text) > 30: # 30ì ì´ìƒì¸ ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ë§Œ
                    text_content.append(text)
            
            full_text = ' '.join(text_content)
            
            if len(full_text) > 200: 
                return f"[ì›ë¬¸ í™•ë³´ ì„±ê³µ]\n{full_text[:3500]}" # ë„ˆë¬´ ê¸¸ë©´ 3500ìì—ì„œ ìë¦„
            else:
                return f"Error: ë³¸ë¬¸ì„ ì°¾ì•˜ìœ¼ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. (ë³´ì•ˆì´ ê°•ë ¥í•œ ì‚¬ì´íŠ¸ì¼ ìˆ˜ ìˆìŒ)\nStatus: {res.status_code}"
                
        else:
            return f"Error: ì‚¬ì´íŠ¸ ì ‘ì† ê±°ë¶€ (Status Code: {res.status_code})"
            
    except Exception as e:
        return f"Error: í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ ({str(e)})"

# ==============================================================================
# [3] í”„ë¡¬í”„íŠ¸ (ì—„ê²©í•œ ë¶„ì„)
# ==============================================================================
PROMPT_BRIEFING = f"""
ROLE: Friendly Investment Tutor.
DATE: {datetime.now().strftime('%Y-%m-%d')}
TASK: Analyze news headlines in KOREAN.

FORMAT:
[ì‹œì¥ ì ìˆ˜] (0~100)
[ì£¼ìš” ì¼ì •] (3 items)
[ì‹œì¥ í•œì¤„í‰] (Friendly tone)
[ìš”ì¦˜ ëœ¨ëŠ” í…Œë§ˆ] (3 items)
[ë‰´ìŠ¤ 3ì¤„ ìš”ì•½]
1. (Title) -> (í˜¸ì¬/ì•…ì¬)
"""

PROMPT_DEEP = """
ROLE: Investment Tutor.
TASK: Analyze the **ORIGINAL ARTICLE TEXT** provided below.
LANGUAGE: **KOREAN ONLY**.

ğŸš¨ **INSTRUCTION:**
1. Analyze based ONLY on the provided text.
2. If the text starts with "Error:", explain WHY you cannot analyze (e.g., "Site blocked access").
3. Do NOT guess if there is an Error.

OUTPUT FORMAT:
**ğŸ“¢ íŒë‹¨:** [ë§¤ìˆ˜ / ë§¤ë„ / ê´€ë§]
**ğŸ’¡ ì´ìœ :** (Summarize the key facts from the text)
**ğŸ“‰ ë¦¬ìŠ¤í¬:** (Risks mentioned in the text)

---
**ğŸ”° ì£¼ë¦°ì´ ìš©ì–´ ì‚¬ì „**
(Explain 2 difficult terms found in the text)
"""

def parse_section(text, header):
    try:
        pattern = re.escape(header) + r"(.*?)(?=\n\[|$)"
        match = re.search(pattern, text, re.DOTALL)
        return match.group(1).strip() if match else ""
    except:
        return ""

# ==============================================================================
# [4] ë©”ì¸ UI
# ==============================================================================
def main():
    if "password_correct" in st.session_state and st.session_state["password_correct"]:
        with st.sidebar:
            if st.button("ë¡œê·¸ì•„ì›ƒ"):
                st.session_state["password_correct"] = False
                st.rerun()

    st.title("ğŸ“ AI ì£¼ì‹ ê³¼ì™¸ ì„ ìƒë‹˜ (ì •ë°€ ë¶„ì„ë°˜)")
    st.caption("ë‰´ìŠ¤ ì›ë¬¸ì„ ì§ì ‘ ëš«ê³  ë“¤ì–´ê°€ì„œ íŒ©íŠ¸ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    if 'deep_results' not in st.session_state:
        st.session_state['deep_results'] = {}

    if 'briefing_data' not in st.session_state:
        status = st.info("ğŸ”„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘ ì¤‘...")
        last, chg, news = fetch_market_data()
        
        if not news:
            status.error("âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
            st.stop()
            
        st.session_state['market_raw'] = (last, chg, news)
        
        news_txt = "\n".join([f"[{i+1}] {n.title}" for i, n in enumerate(news)])
        ai_res, _ = call_ai_relay(f"{PROMPT_BRIEFING}\n{news_txt}")
        
        if ai_res:
            st.session_state['briefing_data'] = ai_res
            status.empty()
        else:
            status.error("ì„œë²„ í˜¼ì¡ (ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„)")
            st.stop()

    last, chg, news = st.session_state.get('market_raw', (None, None, []))
    briefing = st.session_state.get('briefing_data', "")

    if last is not None:
        cols = st.columns(6)
        metrics = [("ë¯¸êµ­ êµ­ì±„ 10ë…„", '^TNX'), ("ê³µí¬ì§€ìˆ˜(VIX)", '^VIX'), ("S&P 500", '^GSPC'), 
                   ("ë‚˜ìŠ¤ë‹¥", '^IXIC'), ("ë¹„íŠ¸ì½”ì¸", 'BTC-USD'), ("ê¸ˆ", 'GC=F')]
        for i, (label, ticker) in enumerate(metrics):
            val = last.get(ticker, 0)
            c = chg.get(ticker, 0)
            cols[i].metric(label, f"{val:,.2f}", f"{c:+.2f}%")

    st.divider()

    score_txt = parse_section(briefing, "[ì‹œì¥ ì ìˆ˜]")
    view_txt = parse_section(briefing, "[ì‹œì¥ í•œì¤„í‰]")
    events_txt = parse_section(briefing, "[ì£¼ìš” ì¼ì •]")
    trending_txt = parse_section(briefing, "[ìš”ì¦˜ ëœ¨ëŠ” í…Œë§ˆ]")
    news_summary_txt = parse_section(briefing, "[ë‰´ìŠ¤ 3ì¤„ ìš”ì•½]")

    c1, c2 = st.columns([1, 3])
    with c1:
        st.metric("ì˜¤ëŠ˜ì˜ ì‹œì¥ ì ìˆ˜", score_txt[:3] if score_txt else "50")
    with c2:
        st.info(f"ğŸ—£ï¸ {view_txt}")

    with st.expander("ğŸ“… ì¼ì • & í…Œë§ˆ", expanded=True):
        c_a, c_b = st.columns(2)
        c_a.write(events_txt)
        c_b.write(trending_txt)

    st.divider()
    if news_summary_txt: st.write(news_summary_txt)

    for i, n in enumerate(news):
        st.divider()
        st.markdown(f"#### {i+1}. {n.title}")
        st.caption(f"ë§í¬: {n.link}")
        
        if st.button(f"ğŸ“– {i+1}ë²ˆ ë‰´ìŠ¤ ì›ë¬¸ ë¶„ì„", key=f"btn_{i}"):
            with st.spinner("ğŸ•µï¸â€â™‚ï¸ ì›ë¬¸ ì‚¬ì´íŠ¸ ì ì… ì¤‘... (ì°¨ë‹¨ ìš°íšŒ ì‹œë„)"):
                # [í•µì‹¬] ì€ì‹ ìˆ  í•¨ìˆ˜ í˜¸ì¶œ
                body = get_article_content(n.link)
                
                # ì›ë¬¸ íšë“ ì„±ê³µ ì—¬ë¶€ í™•ì¸
                if "Error:" in body:
                    st.error(f"âš ï¸ ì›ë¬¸ ì ‘ì† ì‹¤íŒ¨: {body}")
                    st.warning("ì´ ì‚¬ì´íŠ¸ëŠ” ë³´ì•ˆì´ ë„ˆë¬´ ê°•ë ¥í•´ì„œ ë¡œë´‡ ì ‘ì†ì„ ì™„ë²½íˆ ì°¨ë‹¨í–ˆìŠµë‹ˆë‹¤.")
                else:
                    det, _ = call_ai_relay(f"{PROMPT_DEEP}\n{body}")
                    if det:
                        st.session_state['deep_results'][i] = det
                        st.rerun()
                    else:
                        st.error("AI ë¶„ì„ ì‹¤íŒ¨")

        if i in st.session_state['deep_results']:
            with st.chat_message("assistant"):
                st.markdown(st.session_state['deep_results'][i])

    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        if 'briefing_data' in st.session_state: del st.session_state['briefing_data']
        st.rerun()

if __name__ == "__main__":
    main()