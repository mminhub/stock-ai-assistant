import streamlit as st
import feedparser
import yfinance as yf
import requests
import re
import time
from datetime import datetime
import urllib.parse
from bs4 import BeautifulSoup

# ==============================================================================
# [1] ì„¤ì • & ë³´ì•ˆ
# ==============================================================================
st.set_page_config(page_title="AI ì£¼ì‹ ê³¼ì™¸ ì„ ìƒë‹˜", layout="wide")

# 1. ë¡œê·¸ì¸ (ë³´ì•ˆ)
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]:
        return True
    
    st.title("ğŸ”’ ë¡œê·¸ì¸ (Authorized Access Only)")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if st.button("ì ‘ì†"):
        if "APP_PASSWORD" in st.secrets and password == st.secrets["APP_PASSWORD"]:
            st.session_state["password_correct"] = True
            st.rerun()
        else:
            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    return False

if "APP_PASSWORD" in st.secrets:
    if not check_password(): st.stop()

if "GOOGLE_API_KEY" not in st.secrets:
    st.error("ğŸš¨ Secrets ì„¤ì •ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
    st.stop()

API_KEY = st.secrets["GOOGLE_API_KEY"]
RELAY_MODELS = ["gemini-2.5-flash", "gemini-2.0-flash-exp"]

# ==============================================================================
# [2] AI ì—”ì§„ (í•œêµ­ì–´ & ìš©ì–´ ì„¤ëª… íŠ¹í™”)
# ==============================================================================
def clean_text(text):
    if not text: return ""
    text = re.sub(r'<[^>]+>', '', text) # HTML íƒœê·¸ ì œê±°
    return re.sub(r'[\[\]\{\}\"]', '', text).strip()

def call_ai_relay(prompt):
    max_retries = 3
    for attempt in range(max_retries):
        for model in RELAY_MODELS:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={API_KEY}"
            headers = {'Content-Type': 'application/json'}
            data = {"contents": [{"parts": [{"text": prompt}]}]}
            
            try:
                res = requests.post(url, headers=headers, json=data, timeout=30)
                if res.status_code == 200:
                    return res.json()['candidates'][0]['content']['parts'][0]['text'], model
                elif res.status_code == 429:
                    wait_time = 10 * (attempt + 1)
                    # UIì— ë°©í•´ë˜ì§€ ì•Šê²Œ ì¡°ìš©íˆ ëŒ€ê¸°
                    time.sleep(wait_time) 
                    continue
                else:
                    continue
            except:
                continue
    return None, "ì„œë²„ ì‘ë‹µ ì—†ìŒ"

@st.cache_data(ttl=600)
def fetch_market_data():
    try:
        tickers = ['^TNX', '^VIX', 'BTC-USD', 'GC=F', '^GSPC', '^IXIC']
        df = yf.download(tickers, period="5d", progress=False)['Close'].ffill()
        last = df.iloc[-1]
        prev = df.iloc[-2]
        chg = ((last - prev) / prev) * 100
    except:
        last, chg = None, None

    # êµ¬ê¸€ ë‰´ìŠ¤ (ì˜ì–´ ë‰´ìŠ¤ì§€ë§Œ AIê°€ í•œêµ­ì–´ë¡œ ë²ˆì—­í•  ê²ƒì„)
    rss_url = "https://news.google.com/rss/search?q=Finance+Stock+Market&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries: return last, chg, []
        scored_news = []
        for e in feed.entries[:3]:
            # [í•µì‹¬] ì œëª©ê³¼ í•¨ê»˜ 'ìš”ì•½(Snippet)'ë„ ë¯¸ë¦¬ ì €ì¥í•´ë‘  (ì›ë¬¸ ì ‘ì† ì‹¤íŒ¨ ëŒ€ë¹„)
            e.title = clean_text(e.title)
            e['summary_clean'] = clean_text(e.get('summary', ''))
            scored_news.append(e)
        return last, chg, scored_news
    except:
        return last, chg, []

def get_article_content(link, summary_backup):
    """
    ì›ë¬¸ í¬ë¡¤ë§ì„ ì‹œë„í•˜ë˜, ì‹¤íŒ¨í•˜ë©´ RSSì— ìˆë˜ ìš”ì•½ë³¸ì„ ë¦¬í„´í•©ë‹ˆë‹¤.
    ì ˆëŒ€ ë¹ˆ ì†ìœ¼ë¡œ ëŒì•„ê°€ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        res = requests.get(link, headers=headers, timeout=3)
        if res.status_code == 200:
            soup = BeautifulSoup(res.content, 'html.parser')
            text = ' '.join([p.get_text() for p in soup.find_all('p')])
            if len(text) > 200: 
                return text[:2500] # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
    except:
        pass
    
    # í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ, ë°±ì—…í•´ë‘” ìš”ì•½ë³¸ ë¦¬í„´ (ë¹„ìƒìš©)
    return f"[ì›ë¬¸ ì ‘ì† ì°¨ë‹¨ë¨. ìš”ì•½ë³¸ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤]\n{summary_backup}"

# ==============================================================================
# [3] í”„ë¡¬í”„íŠ¸ (í•œêµ­ì–´ ê°•ì œ & ìš©ì–´ ì„¤ëª… ì¶”ê°€)
# ==============================================================================
PROMPT_BRIEFING = f"""
You are a friendly AI Investment Tutor for a college student beginner.
Current Date: {datetime.now().strftime('%Y-%m-%d')}

TASK: Analyze the news headlines and summaries below.
LANGUAGE: **KOREAN ONLY** (Translate everything to Korean).

FORMAT:
[ì‹œì¥ ì ìˆ˜] (0~100ì , ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì•ˆì „/í˜¸í™©)
[ì£¼ìš” ì¼ì •] (ì•ìœ¼ë¡œ ìˆì„ ê²½ì œ ì¼ì • 3ê°œ)
[ì‹œì¥ í•œì¤„í‰] (ì¹œêµ¬ì—ê²Œ ë§í•˜ë“¯ ì‰¬ìš´ ë§íˆ¬ë¡œ)
[ìš”ì¦˜ ëœ¨ëŠ” í…Œë§ˆ] (ì£¼ëª©í• ë§Œí•œ ì„¹í„° 3ê°œ)
[ë‰´ìŠ¤ 3ì¤„ ìš”ì•½]
1. (ë‰´ìŠ¤ ì œëª©) -> (í˜¸ì¬/ì•…ì¬/ì¤‘ë¦½) : ì´ìœ 
2. ...
3. ...
"""

PROMPT_DEEP = """
You are a friendly Investment Tutor.
Analyze the provided text in **KOREAN**.

Target Audience: A college student who is new to stocks.
1. **Translate** complex financial terms into easy Korean concepts.
2. If the text is short (summary only), analyze based on that.

OUTPUT FORMAT:
**ğŸ“¢ íŒë‹¨:** [ë§¤ìˆ˜ / ë§¤ë„ / ê´€ë§]
**ğŸ’¡ ì´ìœ :** (ì´ˆë³´ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…)
**ğŸ“‰ ë¦¬ìŠ¤í¬:** (ì¡°ì‹¬í•´ì•¼ í•  ì )

---
**ğŸ”° ì£¼ë¦°ì´ ìš©ì–´ ì‚¬ì „**
(Pick 2-3 difficult financial terms from the text and explain them simply. 
Example: 'CPI' means Consumer Price Index, which shows inflation...)
"""

def parse_section(text, header):
    try:
        pattern = re.escape(header) + r"(.*?)(?=\n\[|$)"
        match = re.search(pattern, text, re.DOTALL)
        return match.group(1).strip() if match else ""
    except:
        return ""

# ==============================================================================
# [4] ë©”ì¸ UI
# ==============================================================================
def main():
    if "password_correct" in st.session_state and st.session_state["password_correct"]:
        with st.sidebar:
            if st.button("ë¡œê·¸ì•„ì›ƒ"):
                st.session_state["password_correct"] = False
                st.rerun()

    st.title("ğŸ“ ë‚´ ì†ì•ˆì˜ AI ì£¼ì‹ ê³¼ì™¸ ì„ ìƒë‹˜")
    st.caption("ì–´ë ¤ìš´ ì˜ì–´ ë‰´ìŠ¤ë„ í•œêµ­ì–´ë¡œ ì‰½ê²Œ, ëª¨ë¥´ëŠ” ìš©ì–´ëŠ” ì¹œì ˆí•˜ê²Œ!")

    if 'deep_results' not in st.session_state:
        st.session_state['deep_results'] = {}

    if 'briefing_data' not in st.session_state:
        status = st.info("ğŸ”„ ì„ ìƒë‹˜ì´ ë‰´ìŠ¤ ì½ëŠ” ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
        last, chg, news = fetch_market_data()
        
        if not news:
            status.error("âŒ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆì–´ìš”.")
            st.stop()
            
        st.session_state['market_raw'] = (last, chg, news)
        
        # ì œëª© + ìš”ì•½ë³¸ì„ ê°™ì´ ë³´ëƒ„
        news_txt = "\n".join([f"[{i+1}] {n.title}\n(Summary: {n.summary_clean})" for i, n in enumerate(news)])
        
        ai_res, _ = call_ai_relay(f"{PROMPT_BRIEFING}\n{news_txt}")
        
        if ai_res:
            st.session_state['briefing_data'] = ai_res
            status.empty()
            st.toast("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            status.error("ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ì„œë²„ í˜¼ì¡)")
            st.stop()

    last, chg, news = st.session_state.get('market_raw', (None, None, []))
    briefing = st.session_state.get('briefing_data', "")

    # ì§€í‘œ í‘œì‹œ
    if last is not None:
        cols = st.columns(6)
        metrics = [("ë¯¸êµ­ êµ­ì±„ 10ë…„", '^TNX'), ("ê³µí¬ì§€ìˆ˜(VIX)", '^VIX'), ("S&P 500", '^GSPC'), 
                   ("ë‚˜ìŠ¤ë‹¥", '^IXIC'), ("ë¹„íŠ¸ì½”ì¸", 'BTC-USD'), ("ê¸ˆ", 'GC=F')]
        for i, (label, ticker) in enumerate(metrics):
            val = last.get(ticker, 0)
            c = chg.get(ticker, 0)
            cols[i].metric(label, f"{val:,.2f}", f"{c:+.2f}%")

    st.divider()

    # íŒŒì‹±
    score_txt = parse_section(briefing, "[ì‹œì¥ ì ìˆ˜]")
    view_txt = parse_section(briefing, "[ì‹œì¥ í•œì¤„í‰]")
    events_txt = parse_section(briefing, "[ì£¼ìš” ì¼ì •]")
    trending_txt = parse_section(briefing, "[ìš”ì¦˜ ëœ¨ëŠ” í…Œë§ˆ]")
    news_summary_txt = parse_section(briefing, "[ë‰´ìŠ¤ 3ì¤„ ìš”ì•½]")

    # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
    c1, c2 = st.columns([1, 3])
    with c1:
        try:
            score = int(re.search(r'\d+', score_txt).group())
        except: score = 50
        st.metric("ì˜¤ëŠ˜ì˜ ì‹œì¥ ì ìˆ˜", f"{score}ì ")
        st.progress(score)
    with c2:
        st.info(f"ğŸ—£ï¸ **ì„ ìƒë‹˜ í•œë§ˆë””:** {view_txt}")

    with st.expander("ğŸ“… ì£¼ìš” ì¼ì • & í…Œë§ˆ ë³´ë”°ë¦¬", expanded=True):
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown("**[ì£¼ìš” ì¼ì •]**")
            st.write(events_txt)
        with col_b:
            st.markdown("**[ëœ¨ëŠ” í…Œë§ˆ]**")
            st.write(trending_txt)

    st.divider()
    st.subheader("ğŸ“š ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ìˆ˜ì—…")
    
    # ì „ì²´ ìš”ì•½ ë¨¼ì € ë³´ì—¬ì£¼ê¸°
    if news_summary_txt:
        st.markdown(news_summary_txt)
        st.divider()

    # ê°œë³„ ë‰´ìŠ¤ ì¹´ë“œ
    for i, n in enumerate(news):
        with st.container():
            st.markdown(f"#### {i+1}. {n.title}")
            st.caption(f"ì›ë³¸ ë§í¬: {n.link}")
            
            # ì •ë°€ ë¶„ì„ ë²„íŠ¼
            if st.button(f"ğŸ“– {i+1}ë²ˆ ë‰´ìŠ¤ ìì„¸íˆ ë°°ìš°ê¸°", key=f"btn_{i}"):
                with st.spinner("ì„ ìƒë‹˜ì´ ì›ë¬¸ ì½ê³  ì‰½ê²Œ í’€ì´í•˜ëŠ” ì¤‘..."):
                    # ì›ë¬¸ ì ‘ì† ì‹œë„ -> ì‹¤íŒ¨í•˜ë©´ ìš”ì•½ë³¸ ì‚¬ìš© (ì•ˆì „ì¥ì¹˜)
                    body_content = get_article_content(n.link, n.summary_clean)
                    
                    detail, _ = call_ai_relay(f"{PROMPT_DEEP}\nTitle: {n.title}\nContent: {body_content}")
                    
                    if detail:
                        st.session_state['deep_results'][i] = detail
                        st.rerun()
                    else:
                        st.error("ë¶„ì„ ì‹¤íŒ¨ (ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”)")

            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            if i in st.session_state['deep_results']:
                with st.chat_message("assistant"):
                    st.markdown(st.session_state['deep_results'][i])
        
        st.divider()

    if st.button("ğŸ”„ ìˆ˜ì—… ë‹¤ì‹œ ì‹œì‘ (ìƒˆë¡œê³ ì¹¨)"):
        st.cache_data.clear()
        if 'briefing_data' in st.session_state: del st.session_state['briefing_data']
        st.rerun()

if __name__ == "__main__":
    main()