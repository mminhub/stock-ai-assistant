import streamlit as st
import feedparser
import yfinance as yf
import requests
import re
import time
from datetime import datetime
import urllib.parse
from bs4 import BeautifulSoup

# ==============================================================================
# [1] ì„¤ì • (2.5 & 2.0 ì „ìš©)
# ==============================================================================
st.set_page_config(page_title="Strategic AI Partner", layout="wide")

# API í‚¤ í™•ì¸
if "GOOGLE_API_KEY" not in st.secrets:
    st.error("ğŸš¨ Secrets ì„¤ì •ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
    st.info("Streamlit ì‚¬ì´íŠ¸ ì„¤ì •(Settings) -> Secrets ë©”ë‰´ì— GOOGLE_API_KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

API_KEY = st.secrets["GOOGLE_API_KEY"]

# ğŸ‘‡ [í•µì‹¬] ì‚¬ìš©ìë‹˜ í‚¤ì— ë§ëŠ” ìµœì‹  ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
RELAY_MODELS = ["gemini-2.5-flash", "gemini-2.0-flash"]

# ==============================================================================
# [2] AI ë° ë°ì´í„° ì—”ì§„
# ==============================================================================
def clean_text(text):
    if not text: return ""
    return re.sub(r'[\[\]\{\}\"]', '', text).strip()

def call_ai_relay(prompt):
    error_logs = [] 
    for model in RELAY_MODELS:
        # v1beta ì‚¬ìš©
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={API_KEY}"
        headers = {'Content-Type': 'application/json'}
        data = {"contents": [{"parts": [{"text": prompt}]}]}
        
        try:
            res = requests.post(url, headers=headers, json=data, timeout=30)
            
            if res.status_code == 200:
                # ì„±ê³µí•˜ë©´ ë°”ë¡œ ë°˜í™˜
                return res.json()['candidates'][0]['content']['parts'][0]['text'], model
            
            elif res.status_code == 429:
                # ê³¼ë¶€í•˜ ê±¸ë¦¬ë©´ ì ì‹œ ëŒ€ê¸° í›„ ë‹¤ìŒ ëª¨ë¸(2.0)ë¡œ ë„˜ì–´ê°
                time.sleep(1)
                error_logs.append(f"[{model}] 429 ê³¼ë¶€í•˜ (Too Many Requests)")
                continue
            
            else:
                # 404 ë“± ë‹¤ë¥¸ ì—ëŸ¬
                error_logs.append(f"[{model}] Error {res.status_code}: {res.text}")
                continue
                
        except Exception as e:
            error_logs.append(f"[{model}] í†µì‹  ì˜¤ë¥˜: {str(e)}")
            continue
            
    # ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ë©´ ë¡œê·¸ ë°˜í™˜
    return None, "\n".join(error_logs)

@st.cache_data(ttl=600)
def fetch_market_data():
    try:
        tickers = ['^TNX', '^VIX', 'BTC-USD', 'GC=F', '^GSPC', '^IXIC']
        df = yf.download(tickers, period="5d", progress=False)['Close'].ffill()
        last = df.iloc[-1]
        prev = df.iloc[-2]
        chg = ((last - prev) / prev) * 100
    except:
        last, chg = None, None

    # êµ¬ê¸€ ë‰´ìŠ¤ ìˆ˜ì§‘
    # (ì„œë²„ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ ê²€ìƒ‰ì–´ë¥¼ ë‹¨ìˆœí•˜ê²Œ ìœ ì§€)
    rss_url = "https://news.google.com/rss/search?q=Economy+Finance+Bitcoin+Nvidia&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries:
            return last, chg, []
            
        scored_news = []
        for e in feed.entries[:5]: # ìµœì‹  5ê°œ
            e.title = clean_text(e.title)
            scored_news.append(e)
        
        return last, chg, scored_news
        
    except:
        return last, chg, []

def get_article_content(link):
    try:
        res = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'}, timeout=4)
        soup = BeautifulSoup(res.content, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        if len(text) > 200: return text[:3000]
    except:
        pass
    return "ì›ë¬¸ ì ‘ì† ë¶ˆê°€"

# ==============================================================================
# [3] UI ë¡œì§
# ==============================================================================
PROMPT_BRIEFING = f"""
ROLE: Conservative CIO.
DATE: {datetime.now().strftime('%Y-%m-%d')}
INSTRUCTION: Analyze news. Output in KOREAN.
FORMAT:
[MARKET SCORE] (0-100)
[UPCOMING EVENTS] (3 events)
[MARKET VIEW] (1 sentence)
[TRENDING ASSETS] (3 assets)
[NEWS ANALYSIS]
1. ACTION: (Buy/Sell/Hold) | REASON: ...
"""

PROMPT_DEEP = """
Analyze in KOREAN.
GRADE: [S/A/B/C]
ACTION: [ë§¤ìˆ˜/ë§¤ë„/ê´€ë§] | [Reason]
SUMMARY: -Fact
RISK: -Risk
"""

def parse_section(text, header):
    try:
        pattern = re.escape(header) + r"(.*?)(?=\n\[|$)"
        match = re.search(pattern, text, re.DOTALL)
        return match.group(1).strip() if match else ""
    except:
        return ""

def main():
    st.title("â˜• Strategic AI Partner")
    st.caption("Engine: Gemini 2.5 / 2.0 Flash")
    
    if 'deep_results' not in st.session_state:
        st.session_state['deep_results'] = {}

    if 'briefing_data' not in st.session_state:
        status = st.info("ğŸ”„ 2.5 ëª¨ë¸ë¡œ ë¶„ì„ ì¤‘...")
        last, chg, news = fetch_market_data()
        
        if not news:
            status.error("âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ (ì„œë²„ ì°¨ë‹¨). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            st.stop()
            
        st.session_state['market_raw'] = (last, chg, news)
        
        news_txt = "\n".join([f"[{i+1}] {n.title} ({n.get('published', '')})" for i, n in enumerate(news)])
        
        ai_res, error_log = call_ai_relay(f"{PROMPT_BRIEFING}\n{news_txt}")
        
        if ai_res:
            st.session_state['briefing_data'] = ai_res
            st.success("âœ… ì™„ë£Œ")
            time.sleep(1)
            status.empty()
        else:
            status.error("ë¶„ì„ ì‹¤íŒ¨ (ì•„ë˜ ì—ëŸ¬ í™•ì¸)")
            st.code(error_log)
            st.stop()

    last, chg, news = st.session_state.get('market_raw', (None, None, []))
    briefing = st.session_state.get('briefing_data', "")

    if last is not None:
        cols = st.columns(6)
        metrics = [("US 10Y", '^TNX'), ("VIX", '^VIX'), ("S&P 500", '^GSPC'), 
                   ("Nasdaq", '^IXIC'), ("BTC", 'BTC-USD'), ("Gold", 'GC=F')]
        for i, (l, k) in enumerate(metrics):
            cols[i].metric(l, f"{last.get(k,0):,.2f}", f"{chg.get(k,0):.2f}%")

    st.divider()

    # íŒŒì‹± ë° ì¶œë ¥
    score_txt = parse_section(briefing, "[MARKET SCORE]")
    view_txt = parse_section(briefing, "[MARKET VIEW]")
    events_txt = parse_section(briefing, "[UPCOMING EVENTS]")
    trending_txt = parse_section(briefing, "[TRENDING ASSETS]")
    
    c1, c2 = st.columns([1, 3])
    with c1:
        st.metric("Risk Score", score_txt[:3] if score_txt else "50")
    with c2:
        st.info(view_txt if view_txt else "ë¶„ì„ ë‚´ìš© ì—†ìŒ")
        
    with st.expander("ğŸ“… ì¼ì • & ğŸš€ íŠ¸ë Œë“œ", expanded=True):
        st.write(events_txt)
        st.divider()
        st.write(trending_txt)

    st.divider()
    for i, n in enumerate(news):
        st.markdown(f"**{i+1}. {n.title}**")
        st.caption(f"[ì›ë¬¸]({n.link})")
        if st.button("ì •ë°€ ë¶„ì„", key=f"d_{i}"):
            if i in st.session_state['deep_results']:
                st.info("âœ… ì €ì¥ëœ ë¶„ì„")
                st.markdown(st.session_state['deep_results'][i])
            else:
                body = get_article_content(n.link)
                det, err = call_ai_relay(f"{PROMPT_DEEP}\n{body}")
                if det: 
                    st.session_state['deep_results'][i] = det
                    st.info("ë¶„ì„ ì™„ë£Œ")
                    st.markdown(det)
                    st.rerun()
                else: 
                    st.error(err)
        st.divider()

    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        del st.session_state['briefing_data']
        st.rerun()

if __name__ == "__main__":
    main()