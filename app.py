import streamlit as st
import feedparser
import yfinance as yf
import requests
import re
import time
from datetime import datetime
import urllib.parse
from bs4 import BeautifulSoup

# ==============================================================================
# [1] ì„¤ì • (Lite ëª¨ë“œ)
# ==============================================================================
st.set_page_config(page_title="Strategic AI Partner (Lite)", layout="wide")

if "GOOGLE_API_KEY" not in st.secrets:
    st.error("ğŸš¨ Secrets ì„¤ì •ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
    st.stop()

API_KEY = st.secrets["GOOGLE_API_KEY"]

# ì „ëµ: 2.5 -> 2.0 (ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜ ê°€ë³ê²Œ ìš”ì²­)
RELAY_MODELS = ["gemini-2.5-flash", "gemini-2.0-flash-exp"]

# ==============================================================================
# [2] AI ì—”ì§„ (ë‹¤ì´ì–´íŠ¸ ë²„ì „)
# ==============================================================================
def clean_text(text):
    if not text: return ""
    return re.sub(r'[\[\]\{\}\"]', '', text).strip()

def call_ai_relay(prompt):
    error_logs = [] 
    
    for model in RELAY_MODELS:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={API_KEY}"
        headers = {'Content-Type': 'application/json'}
        data = {"contents": [{"parts": [{"text": prompt}]}]}
        
        try:
            res = requests.post(url, headers=headers, json=data, timeout=30)
            
            if res.status_code == 200:
                return res.json()['candidates'][0]['content']['parts'][0]['text'], model
            
            elif res.status_code == 429:
                # [ìˆ˜ì •] ëŒ€ê¸° ì‹œê°„ì„ 10ì´ˆë¡œ ëŒ€í­ ëŠ˜ë¦¼ (í™•ì‹¤í•˜ê²Œ ì‰¬ì—ˆë‹¤ ê°€ê¸°)
                time.sleep(10)
                error_logs.append(f"[{model}] ê³¼ë¶€í•˜ -> 10ì´ˆ ëŒ€ê¸° í›„ êµì²´")
                continue
            
            else:
                error_logs.append(f"[{model}] Error {res.status_code}")
                continue
                
        except Exception as e:
            error_logs.append(f"[{model}] Error: {str(e)}")
            continue
            
    return None, "\n".join(error_logs)

@st.cache_data(ttl=600)
def fetch_market_data():
    try:
        tickers = ['^TNX', '^VIX', 'BTC-USD', 'GC=F', '^GSPC', '^IXIC']
        df = yf.download(tickers, period="5d", progress=False)['Close'].ffill()
        last = df.iloc[-1]
        prev = df.iloc[-2]
        chg = ((last - prev) / prev) * 100
    except:
        last, chg = None, None

    # [ìˆ˜ì •] ë‰´ìŠ¤ ê²€ìƒ‰ì–´ë„ ìµœëŒ€í•œ ì§§ê²Œ
    rss_url = "https://news.google.com/rss/search?q=Finance+Stock&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(rss_url)
        if not feed.entries:
            return last, chg, []
            
        scored_news = []
        # [í•µì‹¬ ìˆ˜ì •] ë‰´ìŠ¤ë¥¼ 3ê°œë§Œ ê°€ì ¸ì˜´ (í† í° ì ˆì•½)
        for e in feed.entries[:3]:
            e.title = clean_text(e.title)
            scored_news.append(e)
        return last, chg, scored_news
    except:
        return last, chg, []

def get_article_content(link):
    try:
        res = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'}, timeout=4)
        soup = BeautifulSoup(res.content, 'html.parser')
        text = ' '.join([p.get_text() for p in soup.find_all('p')])
        if len(text) > 200: return text[:2000] # [ìˆ˜ì •] ë³¸ë¬¸ ê¸¸ì´ë„ 2000ìë¡œ ì œí•œ
    except:
        pass
    return "ì›ë¬¸ ì ‘ì† ë¶ˆê°€"

# ==============================================================================
# [3] UI ë¡œì§
# ==============================================================================
# [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ë„ ë‹¤ì´ì–´íŠ¸ (ì§§ê³  êµµê²Œ)
PROMPT_BRIEFING = f"""
ROLE: CIO.
DATE: {datetime.now().strftime('%Y-%m-%d')}
TASK: Analyze news in KOREAN.
FORMAT:
[MARKET SCORE] (0-100)
[UPCOMING EVENTS] (3 items)
[MARKET VIEW] (1 line)
[TRENDING ASSETS] (3 items)
[NEWS ANALYSIS]
1. ACTION: (Buy/Sell/Hold) | REASON: ...
"""

PROMPT_DEEP = """
Analyze in KOREAN.
ACTION: [Buy/Sell/Hold] | [Reason]
SUMMARY: -Fact
RISK: -Risk
"""

def parse_section(text, header):
    try:
        pattern = re.escape(header) + r"(.*?)(?=\n\[|$)"
        match = re.search(pattern, text, re.DOTALL)
        return match.group(1).strip() if match else ""
    except:
        return ""

def main():
    st.title("â˜• Strategic AI Partner (Lite)")
    
    if 'deep_results' not in st.session_state:
        st.session_state['deep_results'] = {}

    if 'briefing_data' not in st.session_state:
        status = st.info("ğŸ”„ ê°€ë²¼ìš´ ëª¨ë“œë¡œ ë¶„ì„ ì¤‘...")
        last, chg, news = fetch_market_data()
        
        if not news:
            status.error("âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
            st.stop()
            
        st.session_state['market_raw'] = (last, chg, news)
        
        news_txt = "\n".join([f"[{i+1}] {n.title}" for i, n in enumerate(news)])
        
        ai_res, success_model = call_ai_relay(f"{PROMPT_BRIEFING}\n{news_txt}")
        
        if ai_res:
            st.session_state['briefing_data'] = ai_res
            st.success(f"âœ… ì™„ë£Œ ({success_model})")
            time.sleep(1)
            status.empty()
        else:
            status.error("í˜„ì¬ ì„œë²„ í˜¼ì¡ë„ê°€ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. (429 Error)")
            st.warning("íŒ: ìš°ì¸¡ ìƒë‹¨ 'Reboot app'ì„ ëˆŒëŸ¬ì„œ ì„œë²„(IP)ë¥¼ ë°”ê¿”ë³´ì„¸ìš”.")
            st.code(success_model)
            st.stop()

    last, chg, news = st.session_state.get('market_raw', (None, None, []))
    briefing = st.session_state.get('briefing_data', "")

    if last is not None:
        cols = st.columns(6)
        metrics = [("US 10Y", '^TNX'), ("VIX", '^VIX'), ("S&P 500", '^GSPC'), 
                   ("Nasdaq", '^IXIC'), ("BTC", 'BTC-USD'), ("Gold", 'GC=F')]
        for i, (l, k) in enumerate(metrics):
            cols[i].metric(l, f"{last.get(k,0):,.2f}", f"{chg.get(k,0):.2f}%")

    st.divider()

    score_txt = parse_section(briefing, "[MARKET SCORE]")
    view_txt = parse_section(briefing, "[MARKET VIEW]")
    events_txt = parse_section(briefing, "[UPCOMING EVENTS]")
    trending_txt = parse_section(briefing, "[TRENDING ASSETS]")
    
    c1, c2 = st.columns([1, 3])
    with c1:
        st.metric("Risk Score", score_txt[:3] if score_txt else "50")
    with c2:
        st.info(view_txt if view_txt else "ë¶„ì„ ë‚´ìš© ì—†ìŒ")
        
    with st.expander("ğŸ“… ì¼ì • & ğŸš€ íŠ¸ë Œë“œ", expanded=True):
        st.write(events_txt)
        st.divider()
        st.write(trending_txt)

    st.divider()
    for i, n in enumerate(news):
        st.markdown(f"**{i+1}. {n.title}**")
        st.caption(f"[ì›ë¬¸]({n.link})")
        if st.button("ì •ë°€ ë¶„ì„", key=f"d_{i}"):
            if i in st.session_state.get('deep_results', {}):
                st.info("âœ… ì €ì¥ëœ ë¶„ì„")
                st.markdown(st.session_state['deep_results'][i])
            else:
                body = get_article_content(n.link)
                det, succ_model = call_ai_relay(f"{PROMPT_DEEP}\n{body}")
                if det: 
                    st.session_state['deep_results'][i] = det
                    st.success(f"ì™„ë£Œ ({succ_model})")
                    st.rerun()
                else: 
                    st.error(succ_model)
        st.divider()

    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        if 'briefing_data' in st.session_state: del st.session_state['briefing_data']
        st.rerun()

if __name__ == "__main__":
    main()